#!/usr/bin/env python3
import certifi
import requests
import os
from getpass import getpass
import pandas as pd

# --- 1. SSL & CREDENTIALS ---
cert_path = certifi.where()
os.environ["REQUESTS_CA_BUNDLE"] = cert_path
os.environ["SSL_CERT_FILE"] = cert_path

username = input("Enter your Qualys username: ")
password = getpass("Enter your Qualys password: ")

BASE_URL = "https://qualysapi.qg4.apps.qualys.com"
ENDPOINT = "/qps/rest/2.0/search/am/hostasset"
api_endpoint = f"{BASE_URL}{ENDPOINT}"

TAG_NAME = 'Retail Store Prod Deployment 2025'

all_records = []
last_id = 0
has_more = True

print(f"[*] Starting deep extraction for tag: {TAG_NAME}...")

# --- 2. PAGINATED FETCH LOOP ---
try:
    while has_more:
        search_xml = f"""
        <ServiceRequest>
            <preferences>
                <limitResultSize>1000</limitResultSize>
            </preferences>
            <filters>
                <Criteria field="tagName" operator="EQUALS">{TAG_NAME}</Criteria>
                <Criteria field="id" operator="GREATER">{int(last_id)}</Criteria>
            </filters>
            <responseOptions>
                <includeFields>agentInfo.lastCheckedIn,name,address,os,id</includeFields>
            </responseOptions>
        </ServiceRequest>
        """

        response = requests.post(
            api_endpoint,
            auth=(username, password),
            headers={
                "X-Requested-With": "Python",
                "Content-Type": "text/xml",
                "Accept": "application/json"
            },
            data=search_xml,
            timeout=120
        )
        response.raise_for_status()
        data = response.json()

        batch = data.get('ServiceResponse', {}).get('data', [])
        
        if not batch or len(batch) == 0:
            print("[*] No more records returned by API.")
            has_more = False
        else:
            all_records.extend(batch)
            
            # Extract ID from the last item
            last_item = batch[-1]
            possible_id = (
                last_item.get('id') or 
                last_item.get('hostAsset', {}).get('id') or 
                last_item.get('HostAsset', {}).get('id')
            )

            if possible_id is not None:
                last_id = possible_id
                print(f"[*] Batch: {len(batch)} | Total Raw: {len(all_records)} | Current ID: {last_id}")
            else:
                has_more = False
            
            # If the batch is smaller than the requested limit, we've reached the end
            if len(batch) < 1000:
                has_more = False

    # --- 3. DEDUPLICATION & EXPORT ---
    if all_records:
        df = pd.json_normalize(all_records)
        
        # Identify the ID column (it might be 'id' or 'hostAsset.id')
        id_col = next((c for c in df.columns if c.endswith('.id') or c == 'id'), None)
        
        if id_col:
            initial_count = len(df)
            df.drop_duplicates(subset=[id_col], inplace=True)
            print(f"[*] Deduplication: Removed {initial_count - len(df)} duplicate entries.")

        # Date formatting for Power BI
        date_col = next((c for c in df.columns if 'lastCheckedIn' in c), None)
        if date_col:
            df['lastCheckedIn_DT'] = pd.to_datetime(df[date_col]).dt.tz_localize(None)

        output_file = 'qualys_assets_for_pbi.csv'
        df.to_csv(output_file, index=False)
        
        print("-" * 30)
        print(f"[+] TOTAL UNIQUE ASSETS: {len(df)}")
        print(f"[+] File saved to: {os.path.abspath(output_file)}")
        print("-" * 30)
    else:
        print("[!] No assets found.")

except Exception as e:
    print(f"[!] Error: {e}")
