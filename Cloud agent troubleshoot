#!/usr/bin/env python3
import certifi
import requests
import os
from getpass import getpass
import pandas as pd
import io

# --- 1. SSL & CREDENTIALS ---
cert_path = certifi.where()
os.environ["REQUESTS_CA_BUNDLE"] = cert_path
os.environ["SSL_CERT_FILE"] = cert_path

username = input("Enter your Qualys username: ")
password = getpass("Enter your Qualys password: ")

BASE_URL = "https://qualysapi.qg4.apps.qualys.com"
ENDPOINT = "/qps/rest/2.0/search/am/hostasset"
api_endpoint = f"{BASE_URL}{ENDPOINT}"

TAG_NAME = 'Retail Store Prod Deployment 2025'

all_records = []
last_id = 0
has_more = True

print(f"[*] Starting full extraction for tag: {TAG_NAME}...")

# --- 2. PAGINATED FETCH LOOP ---
try:
    while has_more:
        # We use 'id' operator 'GREATER' to fetch the next batch of 100
        search_xml = f"""
        <ServiceRequest>
            <filters>
                <Criteria field="tagName" operator="EQUALS">{TAG_NAME}</Criteria>
                <Criteria field="id" operator="GREATER">{last_id}</Criteria>
            </filters>
            <responseOptions>
                <includeFields>agentInfo.lastCheckedIn,name,address,os,id</includeFields>
            </responseOptions>
        </ServiceRequest>
        """

        response = requests.post(
            api_endpoint,
            auth=(username, password),
            headers={
                "X-Requested-With": "Python",
                "Content-Type": "text/xml",
                "Accept": "application/json"
            },
            data=search_xml,
            timeout=120
        )
        response.raise_for_status()
        data = response.json()

        # Extract the list of hosts from this specific batch
        batch = data.get('ServiceResponse', {}).get('data', [])
        
        if not batch:
            has_more = False
        else:
            all_records.extend(batch)
            
            # Find the ID of the last asset in this batch to use as the starting point for the next
            # We look deep into the JSON: batch -> hostAsset -> id
            last_id = batch[-1].get('hostAsset', {}).get('id')
            
            print(f"[*] Fetched {len(all_records)} assets so far... (Last ID: {last_id})")
            
            # If Qualys returns fewer than 100, we've hit the end of the list
            if len(batch) < 100:
                has_more = False

    # --- 3. EXPORT ALL DATA ---
    if all_records:
        df = pd.json_normalize(all_records)
        
        # We perform the date conversion so Power BI has a clean column to work with,
        # but we do NOT filter the rows out.
        date_col = next((c for c in df.columns if 'lastCheckedIn' in c), None)
        if date_col:
            df['lastCheckedIn_DT'] = pd.to_datetime(df[date_col]).dt.tz_localize(None)
            print(f"[*] Processed {date_col} for Power BI formatting.")

        # Save EVERY asset found to the CSV
        output_file = 'qualys_assets_for_pbi.csv'
        df.to_csv(output_file, index=False)
        
        print("-" * 30)
        print(f"[+] TOTAL EXPORTED: {len(df)} assets")
        print(f"[+] Saved to: {os.path.abspath(output_file)}")
        print("-" * 30)
    else:
        print("[!] No assets were found with that tag.")

except requests.exceptions.HTTPError as e:
    print(f"[!] Qualys API rejected request: {response.text}")
except Exception as e:
    print(f"[!] Script Error: {e}")
